{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "layout: post\n",
    "title: \"「爬虫」豆瓣电影封面海报爬取(下)\"\n",
    "subtitle: 'Python Web 爬虫'\n",
    "author: \"Hufe\"\n",
    "header-img: \"img/post-bg-python.jpg\"\n",
    "header-mask: 0.3\n",
    "mathjax: true\n",
    "tags:\n",
    "  - Python\n",
    "  - 爬虫\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 参考自：[极客时间 数据分析实战45讲 10丨Python爬虫：如何自动化下载王祖贤海报?](https://time.geekbang.org/column/article/76001)  \n",
    ">\n",
    ">\n",
    "> [崔庆才微信公众号  进击的Coder 别只用 Selenium，新神器 Pyppeteer 绕过淘宝更简单！](https://mp.weixin.qq.com/s?__biz=MzIzNzA4NDk3Nw==&mid=2457737358&idx=1&sn=fb88904cac67300130cabbc72bc4a650&chksm=ff44b0d0c83339c6496cabf8e09e8a9e0316df1032ef7523ba6ab7f4f6a4bea1cd4c02eb7d7b&mpshare=1&scene=1&srcid=&key=78b2720e78341aa28774612abcab5307b4cdc9ad1b5d1267c04ee8888a00fe5db69c9a97d040ca8b21302cb3db3ca9ca8f34cc771fde539311540e95369cc90e826f382e4ca3f7e63d92232c425f136a&ascene=1&uin=NzY5MzM5MTAy&devicetype=Windows+10&version=62060739&lang=zh_CN&pass_ticket=bQbopgzSyMCKUcltN1KlYrRMsOkEXodvWIuVZnvFsf26wtcmJtf9Ljz3EkaIyuI8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上篇是通过 JSON 数据爬取，本篇是通过 selenium + webdriver+ XPath 定位爬取。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本次爬取的页面是`https://movie.douban.com/subject_search?search_text=王祖贤&cat=1002\"`  \n",
    "这个页面是 JavaScript 渲染而成的，用基本的 requests 库请求得到的 HTML 结果里面是不包含页面中所见的条目内容的。\n",
    "此类页面可通过模拟浏览器执行，此种情形适用于网页接口和逻辑较为复杂的情况，可以直接以**可见即可爬**的方式进行爬取，如可以使用 Selenium、Splinter、Spynner、pyppeteer、PhantomJS、Splash、requests-html 等来实现。  \n",
    "本篇使用的是Pyppeteer 和 Selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pyppeteer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quotes: 0\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from pyquery import PyQuery as pq\n",
    "\n",
    "url = 'http://quotes.toscrape.com/js/'\n",
    "response = requests.get(url)\n",
    "doc = pq(response.text)\n",
    "print('Quotes:', doc('.quote').length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 安装：\n",
    "`pip install pyppeteer`\n",
    "\n",
    "在 Pyppetter 中，实际上它背后也是有一个类似 Chrome 浏览器的 Chromium 浏览器在执行一些动作进行网页渲染，具体内容请看崔大的文章  \n",
    "所以，第一次使用pyppeteer，会自动安装chromium\n",
    "```\n",
    "[W:pyppeteer.chromium_downloader] start chromium download.\n",
    "Download may take a few minutes.\n",
    "100%|███████████████████████████████████████████████████████████████| 133194757/133194757 [00:25<00:00, 5263685.65it/s]\n",
    "[W:pyppeteer.chromium_downloader] \n",
    "chromium download done.\n",
    "[W:pyppeteer.chromium_downloader] chromium extracted to: C:\\Users\\huife\\AppData\\Local\\pyppeteer\\pyppeteer\\local-chromium\\575458and\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from pyppeteer import launch\n",
    "from pyquery import PyQuery as pq\n",
    "\n",
    "async def main():\n",
    "    browser = await launch()\n",
    "    page = await browser.newPage()\n",
    "    await page.goto('http://quotes.toscrape.com/js/')\n",
    "    doc = pq(await page.content())\n",
    "    print('Quotes:', doc('.quote').length)\n",
    "    await browser.close()\n",
    "\n",
    "asyncio.get_event_loop().run_until_complete(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Quotes: 10\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](https://raw.githubusercontent.com/hufe09/GitNote-Images/master/gitnote/2019/05/14/1557845283427-1557845284044.png)\n",
    "```\n",
    "<div class=\"quote\">\n",
    "    <span class=\"text\">“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”</span>\n",
    "    <span>by<small class=\"author\">Albert Einstein</small></span>\n",
    "    <div class=\"tags\">Tags:\n",
    "        <a class=\"tag\">change</a>\n",
    "        <a class=\"tag\">deep-thoughts</a>\n",
    "        <a class=\"tag\">thinking</a>\n",
    "        <a class=\"tag\">world</a>\n",
    "    </div>\n",
    "</div>\n",
    "```\n",
    "```\n",
    "<script>\n",
    "    var data = [\n",
    "    {\n",
    "        \"tags\": [\n",
    "            \"change\",\n",
    "            \"deep-thoughts\",\n",
    "            \"thinking\",\n",
    "            \"world\"\n",
    "        ],\n",
    "        \"author\": {\n",
    "            \"name\": \"Albert Einstein\",\n",
    "            \"goodreads_link\": \"/author/show/9810.Albert_Einstein\",\n",
    "            \"slug\": \"Albert-Einstein\"\n",
    "        },\n",
    "        \"text\": \"\\u201cThe world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.\\u201d\"\n",
    "    },\n",
    "    {\n",
    "        \"tags\": [\n",
    "            \"abilities\",\n",
    "            \"choices\"\n",
    "        ],\n",
    "        \"author\": {\n",
    "            \"name\": \"J.K. Rowling\",\n",
    "            \"goodreads_link\": \"/author/show/1077326.J_K_Rowling\",\n",
    "            \"slug\": \"J-K-Rowling\"\n",
    "        },\n",
    "        \"text\": \"\\u201cIt is our choices, Harry, that show what we truly are, far more than our abilities.\\u201d\"\n",
    "    }\n",
    "];\n",
    "    for (var i in data) {\n",
    "        var d = data[i];\n",
    "        var tags = $.map(d['tags'], function(t) {\n",
    "            return \"<a class='tag'>\" + t + \"</a>\";\n",
    "        }).join(\" \");\n",
    "        document.write(\"<div class='quote'><span class='text'>\" + d['text'] + \"</span><span>by <small class='author'>\" + d['author']['name'] + \"</small></span><div class='tags'>Tags: \" + tags + \"</div></div>\");\n",
    "        }\n",
    "</script>\n",
    "```\n",
    "查看js代码，其`<div class=\"quote\">`盒子的显示数据是通过for循环遍历数组data内的json渲染到页面中的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from pyquery import PyQuery as pq\n",
    "\n",
    "url = 'https://movie.douban.com/subject_search?search_text=王祖贤&cat=1002'\n",
    "response = requests.get(url)\n",
    "doc = pq(response.text)\n",
    "print('Covers:', doc('.cover').length)\n",
    "\n",
    "import asyncio\n",
    "from pyppeteer import launch\n",
    "from pyquery import PyQuery as pq\n",
    "\n",
    "async def main():\n",
    "    browser = await launch()\n",
    "    page = await browser.newPage()\n",
    "    # await page.goto('http://quotes.toscrape.com/js/')\n",
    "    await page.goto(url)\n",
    "\n",
    "    doc = pq(await page.content())\n",
    "    print('Covers:', doc('.cover').length)\n",
    "    await browser.close()\n",
    "\n",
    "asyncio.get_event_loop().run_until_complete(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Covers: 0\n",
    "```\n",
    "用pyppeteer抓取页面，发现没有任何结果。  \n",
    "此方法对[豆瓣电影](https://movie.douban.com/subject_search?search_text=王祖贤&cat=1002)不适用。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当我们直接用 Requests 获取本页面HTML 的时候，发现想要的 XPath 并不存在。这是因为 HTML 还没有加载完，因此你需要一个工具，来进行网页加载的模拟，直到完成加载后再给你完整的 HTML。\n",
    "\n",
    "在 Python 中，这个工具就是 Selenium 库，使用方法如下：\n",
    "```\n",
    "from selenium import webdriver\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(request_url)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Selenium` 是 Web 应用的测试工具，可以直接运行在浏览器中，它的原理是模拟用户在进行操作，支持当前多种主流的浏览器。\n",
    "\n",
    "这里我们模拟 Chrome 浏览器的页面访问。\n",
    "\n",
    "你需要先引用 Selenium 中的 WebDriver 库。WebDriver 实际上就是 Selenium 2，是一种用于 Web 应用程序的自动测试工具，提供了一套友好的 API，方便我们进行操作。\n",
    "\n",
    "然后通过 WebDriver 创建一个 Chrome 浏览器的 drive，再通过 drive 获取访问页面的完整 HTML。\n",
    "\n",
    "当你获取到完整的 HTML 时，就可以对 HTML 中的 XPath 进行提取，在这里我们需要找到图片地址 srcs 和电影名称 titles。这里通过 XPath 语法匹配到了多个元素，因为是多个元素，所以我们需要用 for 循环来对每个元素进行提取。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "但 Selenium 用的时候有个麻烦事，就是环境的相关配置，得安装好相关浏览器，比如 Chrome、Firefox 等等，然后还要到官方网站去下载对应的驱动，最重要的还需要安装对应的 Python Selenium 库，确实是不是很方便，另外如果要做大规模部署的话，环境配置的一些问题也是个头疼的事情。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Chrome\n",
    "点击下载chrome的webdriver： http://chromedriver.storage.googleapis.com/index.html  \n",
    "不同的Chrome的版本对应的chromedriver.exe 版本也不一样，下载时不要搞错了。如果是最新的Chrome, 下载最新的chromedriver.exe 就可以了。  \n",
    "把chromedriver的路径也加到环境变量里。  \n",
    " \n",
    "- Firefox\n",
    "Firefox驱动下载地址为：https://github.com/mozilla/geckodriver/releases/  \n",
    "根据自己的操作系统下载对应的驱动即可，使用的话，需要把驱动的路径和火狐浏览器的路径加入到环境变量里面才可以  \n",
    " \n",
    "- IE\n",
    "IE浏览器驱动下载地址为：http://selenium-release.storage.googleapis.com/index.html  \n",
    "根据自己selenium版本下载对应版本的驱动即可，python的话，下载里面的IEDriverServerxxx.zip即可，这个是区分32和64位系统的，根据自己的系统下载即可，需要注意的是，如果要打开IE浏览器的话，需要在浏览器的Internet选项中的安全页里有4个安全选项，Internet、本地Internet、受信任的站点、受限制的站点，这4个里面都有一个启用保护模式，都需要勾选上才可以，还得把驱动的路径加入到环境变量中。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selenium使用\n",
    "如果不想让Chrome页面启动，可以配置为headless模式，这样在启动的时候我们便看不到任何界面了。  \n",
    "\n",
    "Tips：如果下载的chromedriver没有添加到环境变量里面，需要在`webdriver.Chrome()`中填写chromedriver路径。例如：`webdriver.Chrome(‘../chromedriver.exe’)`\n",
    "\n",
    "- 添加环境变量\n",
    "  - [Windows](https://blog.csdn.net/qq_41429288/article/details/80472064)\n",
    "  - [Mac](https://blog.csdn.net/ywj_486/article/details/80940087)\n",
    "  - Linux  \n",
    "      在命令行中中进入下载文件所在路径，将其移动到/usr/bin  \n",
    "      `sudo mv chromedriver /usr/bin`\n",
    "\n",
    "运行之后会出现一个空白的 Chrom界面\n",
    "![title](https://raw.githubusercontent.com/hufe09/GitNote-Images/master/gitnote/2019/05/14/1557764947071-1557764947079.png)\n",
    "加载结束\n",
    "![title](https://raw.githubusercontent.com/hufe09/GitNote-Images/master/gitnote/2019/05/14/1557764454475-1557764454500.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from lxml import etree\n",
    "\n",
    "def chrome_driver(url):\n",
    "    driver = webdriver.Chrome()\n",
    "    # 使用headless模式\n",
    "#     driver = chrome_headless()\n",
    "    # 请求地址\n",
    "    driver.get(url)\n",
    "    # 对当前屏幕截图\n",
    "    driver.get_screenshot_as_file(\"screenshot.png\")\n",
    "    # 打印源页面\n",
    "    # print(driver.page_source)\n",
    "    html = etree.HTML(driver.page_source)\n",
    "    # 关闭浏览器\n",
    "    driver.close()\n",
    "    # 退出webdriver\n",
    "    driver.quit()\n",
    "    return html\n",
    "\n",
    "def chrome_headless():   \n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument('--no-sandbox')\n",
    "    # 使用headless模式：不打开浏览器\n",
    "    chrome_options.add_argument('--headless')\n",
    "    # 谷歌文档提到需要加上这个属性来规避bug\n",
    "    chrome_options.add_argument('--disable-gpu')\n",
    "    # 初始化实例\n",
    "    driver = webdriver.Chrome(chrome_options=chrome_options)\n",
    "    return driver\n",
    "url = 'https://movie.douban.com/subject_search?search_text=王祖贤&cat=1002'\n",
    "html = chrome_driver(url)\n",
    "src_xpath = \"//div[@class='item-root']/a[@class='cover-link']/img[@class='cover']/@src\"\n",
    "title_xpath = \"//div[@class='item-root']/div[@class='detail']/div[@class='title']/a[@class='title-text']\"\n",
    "srcs = html.xpath(src_xpath)\n",
    "titles = html.xpath(title_xpath)\n",
    "print(f'Srcs:{len(srcs)}, Titles:{len(titles)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "未使用headless模式，结果如下，爬取成功\n",
    "```\n",
    "Srcs:16, Titles:16\n",
    "```\n",
    "使用headless模式，结果为0，爬取失败\n",
    "```\n",
    "Srcs:0, Titles:0\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "完整爬取代码："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "WebDriverException",
     "evalue": "Message: unknown error: Chrome failed to start: exited abnormally\n  (unknown error: DevToolsActivePort file doesn't exist)\n  (The process started from chrome location /usr/bin/google-chrome is no longer running, so ChromeDriver is assuming that Chrome has crashed.)\n  (Driver info: chromedriver=74.0.3729.6 (255758eccf3d244491b8a1317aa76e1ce10d57e9-refs/branch-heads/3729@{#29}),platform=Linux 4.15.0-29-generic x86_64)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mWebDriverException\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-7ece6f82da64>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-7ece6f82da64>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    163\u001b[0m     \u001b[0;31m#单线程\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0murl\u001b[0m \u001b[0;32min\u001b[0m \u001b[0murls\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcrawling_cover\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m     \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Download Finished!\\n耗时{end - start}秒'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-7ece6f82da64>\u001b[0m in \u001b[0;36mcrawling_cover\u001b[0;34m(url, query)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;31m# 获取html内容，方法2：Chrome Webdriver\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m     \u001b[0mhtml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchrome_driver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0;31m# 解析html内容，方法2：Xpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-7ece6f82da64>\u001b[0m in \u001b[0;36mchrome_driver\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mchrome_driver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0mdriver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwebdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mChrome\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0;31m# 使用headless模式\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;31m# driver = chrome_headless()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, executable_path, port, options, service_args, desired_capabilities, service_log_path, chrome_options, keep_alive)\u001b[0m\n\u001b[1;32m     79\u001b[0m                     \u001b[0mremote_server_addr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mservice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mservice_url\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m                     keep_alive=keep_alive),\n\u001b[0;32m---> 81\u001b[0;31m                 desired_capabilities=desired_capabilities)\n\u001b[0m\u001b[1;32m     82\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, command_executor, desired_capabilities, browser_profile, proxy, keep_alive, file_detector, options)\u001b[0m\n\u001b[1;32m    155\u001b[0m             warnings.warn(\"Please use FirefoxOptions to set browser profile\",\n\u001b[1;32m    156\u001b[0m                           DeprecationWarning, stacklevel=2)\n\u001b[0;32m--> 157\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcapabilities\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbrowser_profile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_switch_to\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSwitchTo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mobile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMobile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36mstart_session\u001b[0;34m(self, capabilities, browser_profile)\u001b[0m\n\u001b[1;32m    250\u001b[0m         parameters = {\"capabilities\": w3c_caps,\n\u001b[1;32m    251\u001b[0m                       \"desiredCapabilities\": capabilities}\n\u001b[0;32m--> 252\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCommand\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNEW_SESSION\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'sessionId'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'value'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[1;32m    323\u001b[0m                 response.get('value', None))\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/selenium/webdriver/remote/errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m    240\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'alert'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_value_or_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mWebDriverException\u001b[0m: Message: unknown error: Chrome failed to start: exited abnormally\n  (unknown error: DevToolsActivePort file doesn't exist)\n  (The process started from chrome location /usr/bin/google-chrome is no longer running, so ChromeDriver is assuming that Chrome has crashed.)\n  (Driver info: chromedriver=74.0.3729.6 (255758eccf3d244491b8a1317aa76e1ce10d57e9-refs/branch-heads/3729@{#29}),platform=Linux 4.15.0-29-generic x86_64)\n"
     ]
    }
   ],
   "source": [
    "# cover_parse.py\n",
    "import os\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed, wait, ALL_COMPLETED\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "import requests\n",
    "from lxml import etree\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "\n",
    "def download(src, img_name, query):\n",
    "    \"\"\"\" 下载图片 \"\"\"\n",
    "    # print('启动下载进程，进程号[%d].' % os.getpid())\n",
    "    dir = './' + query + '/' + str(img_name).strip('\\u200e') + '.jpg'\n",
    "    try:\n",
    "        pic = requests.get(src, timeout=10)\n",
    "        fp = open(dir, 'wb')\n",
    "        fp.write(pic.content)\n",
    "        fp.close()\n",
    "        return '开始下载:' + str(img_name).strip('\\u200e')\n",
    "    except requests.exceptions.ConnectionError:\n",
    "        return str(img_name) + '无法下载!'\n",
    "    except OSError:\n",
    "        return str(img_name) + '无法下载!'\n",
    "\n",
    "\n",
    "def chrome_headless():\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument('--no-sandbox')\n",
    "    # 使用headless模式：不打开浏览器\n",
    "    chrome_options.add_argument('--headless')\n",
    "    # 谷歌文档提到需要加上这个属性来规避bug\n",
    "    chrome_options.add_argument('--disable-gpu')\n",
    "    # 初始化实例\n",
    "    driver = webdriver.Chrome(chrome_options=chrome_options)\n",
    "    return driver\n",
    "\n",
    "\n",
    "def chrome_driver(url):\n",
    "    driver = webdriver.Chrome()\n",
    "    # 使用headless模式\n",
    "    # driver = chrome_headless()\n",
    "    # 请求地址\n",
    "    driver.get(url)\n",
    "    # 对当前屏幕截图\n",
    "    driver.get_screenshot_as_file(\"screenshot.png\")\n",
    "    # 打印源页面\n",
    "    # print(driver.page_source)\n",
    "    html = etree.HTML(driver.page_source)\n",
    "    # 关闭浏览器\n",
    "    driver.close()\n",
    "    # 退出webdriver\n",
    "    driver.quit()\n",
    "    return html\n",
    "\n",
    "\n",
    "def multi_threads_pool(num, func, lists):\n",
    "    \"\"\"线程池下载\"\"\"\n",
    "    threads_pool = ThreadPoolExecutor(num)\n",
    "    threads = [threads_pool.submit(lambda p: func(*p), list) for list in lists]\n",
    "    # for t in threads:\n",
    "    #     print(t.done())\n",
    "\n",
    "    for future in as_completed(threads):\n",
    "        # 使用as_completed方法一次取出所有任务的结果\n",
    "        data = future.result()\n",
    "        print(f\"{data}\")\n",
    "    # wait方法可以让主线程阻塞，直到满足设定的要求\n",
    "    wait(threads, return_when=ALL_COMPLETED)\n",
    "\n",
    "def multi_process_pool(num, func, lists, query):\n",
    "    '''进程池'''\n",
    "    processes_pool = ProcessPoolExecutor(max_workers=num)\n",
    "    # processes = [processes_pool.submit(lambda p: func(*p), list) for list in lists]\n",
    "    processes = [processes_pool.submit(func, list, query) for list, query in zip(lists, [query] * len(lists))]\n",
    "    for processe in as_completed(processes):\n",
    "        # 使用as_completed方法一次取出所有任务的结果\n",
    "        data = processe.result()\n",
    "        print(f\"{data}\")\n",
    "    # process_results = [task.result() for task in as_completed(processes)]\n",
    "    # print(process_results)\n",
    "    wait(processes, return_when=ALL_COMPLETED)\n",
    "\n",
    "\n",
    "def single_thread(srcs, titles, query):\n",
    "    i = 1\n",
    "    for src, title in zip(srcs, titles):\n",
    "        print(f'正在下载第{i}张图片')\n",
    "        download(src, title.text, query)\n",
    "        i += 1\n",
    "\n",
    "\n",
    "def crawling_cover(url, query):\n",
    "    # 获取html内容，方法1：\n",
    "    # requests获取源网页，BeautifulSoup解析\n",
    "    # response = requests.get(url)\n",
    "    # html = BeautifulSoup(response.content, 'lxml')\n",
    "    # srcs = html.find('.item-root .detail .cover src')\n",
    "    # titles = html.find('.item-root .cover-link .title')\n",
    "\n",
    "    # 获取html内容，方法2：Chrome Webdriver\n",
    "    html = chrome_driver(url)\n",
    "\n",
    "    # 解析html内容，方法2：Xpath\n",
    "    src_xpath = \"//div[@class='item-root']/a[@class='cover-link']/img[@class='cover']/@src\"\n",
    "    title_xpath = \"//div[@class='item-root']/div[@class='detail']/div[@class='title']/a[@class='title-text']\"\n",
    "    srcs = html.xpath(src_xpath)\n",
    "    titles = html.xpath(title_xpath)\n",
    "\n",
    "    lists = []\n",
    "    for src, title, q in zip(srcs, titles, [query] * len(srcs)):\n",
    "        print(src, title.text)\n",
    "        lists.append([src, title.text, q])\n",
    "\n",
    "    start = time.time()\n",
    "    print('启动下载进程，进程号[%d].' % os.getpid())\n",
    "    # 线程池下载\n",
    "    multi_threads_pool(8, download, lists)\n",
    "\n",
    "    # 单线程下载\n",
    "    # single_thread(srcs, titles, query)\n",
    "\n",
    "    end = time.time()\n",
    "    print('本次下载耗时%.2f秒.' % (end - start))\n",
    "    \n",
    "    values = url.split('?')[- 1]\n",
    "    gets = {}\n",
    "    for key_value in values.split('&'):\n",
    "        list = key_value.split('=')\n",
    "        gets[list[0]] = list[1]\n",
    "    if (gets.__contains__('start')):\n",
    "        page = int(gets['start']) // 15 + 1\n",
    "        pages = '------------------------已爬取第'+ str(page) +'页----------------------------------'\n",
    "    else:\n",
    "        pages = '------------------------已爬取第1页----------------------------------'\n",
    "    return pages\n",
    "\n",
    "def main():\n",
    "\n",
    "    query = '王祖贤'\n",
    "    # 创建文件夹\n",
    "    folder_name = query\n",
    "    if not os.path.exists(folder_name):\n",
    "        os.makedirs(folder_name)\n",
    "\n",
    "    urls = []\n",
    "    for i in range(0, 15 * 2, 15):\n",
    "        if i == 0:\n",
    "            urls.append(\"https://movie.douban.com/subject_search?search_text=\" + query + \"&cat=1002\")\n",
    "        else:\n",
    "            urls.append(\"https://movie.douban.com/subject_search?search_text=\" + query + \"&cat=1002&start=\" + str(i))\n",
    "\n",
    "    lists = []\n",
    "    for url, q in zip(urls, [query] * len(urls)):\n",
    "        lists.append([url, q])\n",
    "    start = time.time()\n",
    "    \n",
    "    #使用进程池，进程数为2\n",
    "    #multi_process_pool(2, crawling_cover, urls, query)\n",
    "    \n",
    "    #单线程\n",
    "    for url in urls:\n",
    "        print(crawling_cover(url, query))\n",
    "    end = time.time()\n",
    "    print(f'Download Finished!\\n耗时{end - start}秒')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](https://raw.githubusercontent.com/hufe09/GitNote-Images/master/gitnote/2019/05/14/1557764874462-1557764874485.png)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
